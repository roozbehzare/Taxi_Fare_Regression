{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP-Djv_14nVW"
      },
      "source": [
        "# Data Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kczh2UIJTl1",
        "outputId": "a2162de6-7042-49f5-cbf2-635583f29612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/kaggle\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0j3RvrG_KxD"
      },
      "source": [
        "You're setting up access to your Google Drive and letting your code use your Kaggle API key from a folder inside your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8UK7IaIJpyy",
        "outputId": "1d2eb4ab-a245-4e6f-bfd7-13b07a3da18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data\n",
            "License(s): U.S. Government Works\n",
            "Downloading nyc-yellow-taxi-trip-data.zip to /content\n",
            " 99% 1.77G/1.78G [00:10<00:00, 272MB/s]\n",
            "100% 1.78G/1.78G [00:10<00:00, 189MB/s]\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "! kaggle datasets download elemento/nyc-yellow-taxi-trip-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc9cIaQr_TmU"
      },
      "source": [
        "You’re downloading a dataset from Kaggle directly into Colab using the Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxz-XhVpJ2kL",
        "outputId": "c5b9e168-bf32-432e-f125-befeb10395dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/nyc-yellow-taxi-trip-data.zip\n",
            "  inflating: yellow_tripdata_2015-01.csv  \n",
            "  inflating: yellow_tripdata_2016-01.csv  \n",
            "  inflating: yellow_tripdata_2016-02.csv  \n",
            "  inflating: yellow_tripdata_2016-03.csv  \n"
          ]
        }
      ],
      "source": [
        "! unzip /content/nyc-yellow-taxi-trip-data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfevHZK5Crqr"
      },
      "source": [
        "Unzips the downloaded file so you can use the .csv dataset inside."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyPq7Ubu7ZgF"
      },
      "source": [
        "# Data Prepration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ThKp9tdE5c7v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJMtUAadC9vK"
      },
      "source": [
        "Imports the libraries needed for:\n",
        "\n",
        "Data handling (pandas, numpy)\n",
        "\n",
        "Visualization (seaborn, matplotlib)\n",
        "\n",
        "Preprocessing labels (LabelEncoder)\n",
        "\n",
        "Hides warnings to make output cleaner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "JrbGb7_Q7940",
        "outputId": "ec7a11d3-d52c-4a19-a9f0-98beb1c00f68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
              "0                2  2016-01-01 00:00:00   2016-01-01 00:00:00   \n",
              "1                2  2016-01-01 00:00:00   2016-01-01 00:00:00   \n",
              "2                2  2016-01-01 00:00:00   2016-01-01 00:00:00   \n",
              "3                2  2016-01-01 00:00:00   2016-01-01 00:00:00   \n",
              "4                2  2016-01-01 00:00:00   2016-01-01 00:00:00   \n",
              "...            ...                  ...                   ...   \n",
              "10906853         2  2016-01-31 23:30:32   2016-01-31 23:38:18   \n",
              "10906854         1  2016-01-05 00:15:55   2016-01-05 00:16:06   \n",
              "10906855         1  2016-01-05 06:12:46   2016-03-19 20:45:50   \n",
              "10906856         1  2016-01-05 06:21:44   2016-03-28 12:54:26   \n",
              "10906857         1  2016-01-05 06:15:21   2016-01-05 06:15:36   \n",
              "\n",
              "          passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
              "0                       2           1.10        -73.990372        40.734695   \n",
              "1                       5           4.90        -73.980782        40.729912   \n",
              "2                       1          10.54        -73.984550        40.679565   \n",
              "3                       1           4.75        -73.993469        40.718990   \n",
              "4                       3           1.76        -73.960625        40.781330   \n",
              "...                   ...            ...               ...              ...   \n",
              "10906853                1           2.20        -74.003578        40.751011   \n",
              "10906854                1           0.00        -73.945488        40.751530   \n",
              "10906855                3           1.40        -73.994240        40.766586   \n",
              "10906856                1           2.10        -73.948067        40.776531   \n",
              "10906857                3           0.00        -73.960938        40.758595   \n",
              "\n",
              "          RatecodeID store_and_fwd_flag  dropoff_longitude  dropoff_latitude  \\\n",
              "0                  1                  N         -73.981842         40.732407   \n",
              "1                  1                  N         -73.944473         40.716679   \n",
              "2                  1                  N         -73.950272         40.788925   \n",
              "3                  1                  N         -73.962242         40.657333   \n",
              "4                  1                  N         -73.977264         40.758514   \n",
              "...              ...                ...                ...               ...   \n",
              "10906853           1                  N         -73.982651         40.767509   \n",
              "10906854           1                  N         -73.945457         40.751530   \n",
              "10906855           1                  N         -73.984428         40.753922   \n",
              "10906856           1                  N         -73.978188         40.777435   \n",
              "10906857           2                  N         -73.961006         40.758583   \n",
              "\n",
              "          payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
              "0                    2          7.5    0.5      0.5        0.00          0.00   \n",
              "1                    1         18.0    0.5      0.5        0.00          0.00   \n",
              "2                    1         33.0    0.5      0.5        0.00          0.00   \n",
              "3                    2         16.5    0.0      0.5        0.00          0.00   \n",
              "4                    2          8.0    0.0      0.5        0.00          0.00   \n",
              "...                ...          ...    ...      ...         ...           ...   \n",
              "10906853             2          8.5    0.5      0.5        0.00          0.00   \n",
              "10906854             2          2.5    0.5      0.5        0.00          0.00   \n",
              "10906855             2          7.5    0.5      0.5        0.00          0.00   \n",
              "10906856             1         11.5    0.0      0.5        2.45          0.00   \n",
              "10906857             2         52.0    0.0      0.5        0.00          5.54   \n",
              "\n",
              "          improvement_surcharge  total_amount  \n",
              "0                           0.3          8.80  \n",
              "1                           0.3         19.30  \n",
              "2                           0.3         34.30  \n",
              "3                           0.3         17.30  \n",
              "4                           0.3          8.80  \n",
              "...                         ...           ...  \n",
              "10906853                    0.3          9.80  \n",
              "10906854                    0.3          3.80  \n",
              "10906855                    0.3          8.80  \n",
              "10906856                    0.3         14.75  \n",
              "10906857                    0.3         58.34  \n",
              "\n",
              "[10906858 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d939787c-8f03-4ef7-9dd5-ffa3dad1649f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>tpep_pickup_datetime</th>\n",
              "      <th>tpep_dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>-73.990372</td>\n",
              "      <td>40.734695</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.981842</td>\n",
              "      <td>40.732407</td>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>4.90</td>\n",
              "      <td>-73.980782</td>\n",
              "      <td>40.729912</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.944473</td>\n",
              "      <td>40.716679</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>19.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>10.54</td>\n",
              "      <td>-73.984550</td>\n",
              "      <td>40.679565</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.950272</td>\n",
              "      <td>40.788925</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>34.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>4.75</td>\n",
              "      <td>-73.993469</td>\n",
              "      <td>40.718990</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.962242</td>\n",
              "      <td>40.657333</td>\n",
              "      <td>2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>17.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>1.76</td>\n",
              "      <td>-73.960625</td>\n",
              "      <td>40.781330</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.977264</td>\n",
              "      <td>40.758514</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906853</th>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-31 23:30:32</td>\n",
              "      <td>2016-01-31 23:38:18</td>\n",
              "      <td>1</td>\n",
              "      <td>2.20</td>\n",
              "      <td>-74.003578</td>\n",
              "      <td>40.751011</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.982651</td>\n",
              "      <td>40.767509</td>\n",
              "      <td>2</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>9.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906854</th>\n",
              "      <td>1</td>\n",
              "      <td>2016-01-05 00:15:55</td>\n",
              "      <td>2016-01-05 00:16:06</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-73.945488</td>\n",
              "      <td>40.751530</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.945457</td>\n",
              "      <td>40.751530</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906855</th>\n",
              "      <td>1</td>\n",
              "      <td>2016-01-05 06:12:46</td>\n",
              "      <td>2016-03-19 20:45:50</td>\n",
              "      <td>3</td>\n",
              "      <td>1.40</td>\n",
              "      <td>-73.994240</td>\n",
              "      <td>40.766586</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.984428</td>\n",
              "      <td>40.753922</td>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906856</th>\n",
              "      <td>1</td>\n",
              "      <td>2016-01-05 06:21:44</td>\n",
              "      <td>2016-03-28 12:54:26</td>\n",
              "      <td>1</td>\n",
              "      <td>2.10</td>\n",
              "      <td>-73.948067</td>\n",
              "      <td>40.776531</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.978188</td>\n",
              "      <td>40.777435</td>\n",
              "      <td>1</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>14.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906857</th>\n",
              "      <td>1</td>\n",
              "      <td>2016-01-05 06:15:21</td>\n",
              "      <td>2016-01-05 06:15:36</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-73.960938</td>\n",
              "      <td>40.758595</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>-73.961006</td>\n",
              "      <td>40.758583</td>\n",
              "      <td>2</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.54</td>\n",
              "      <td>0.3</td>\n",
              "      <td>58.34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10906858 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d939787c-8f03-4ef7-9dd5-ffa3dad1649f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d939787c-8f03-4ef7-9dd5-ffa3dad1649f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d939787c-8f03-4ef7-9dd5-ffa3dad1649f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2dbfad6-91ff-42e0-bc3d-2aa56ad5097a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2dbfad6-91ff-42e0-bc3d-2aa56ad5097a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2dbfad6-91ff-42e0-bc3d-2aa56ad5097a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = pd.read_csv('/content/yellow_tripdata_2016-01.csv')\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRf6Et6vDOb8"
      },
      "source": [
        "Loads the taxi trip data CSV file into a pandas DataFrame named df.\n",
        "\n",
        "Displays the full DataFrame in output (shows a table of the data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "orIVeeAp8upg",
        "outputId": "81aae8fe-aad2-4947-e39b-a7bf33fc6fa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           VendorID  passenger_count  trip_distance  pickup_longitude  \\\n",
              "count  1.090686e+07     1.090686e+07   1.090686e+07      1.090686e+07   \n",
              "mean   1.535024e+00     1.670847e+00   4.648197e+00     -7.281869e+01   \n",
              "std    4.987718e-01     1.324891e+00   2.981095e+03      9.168964e+00   \n",
              "min    1.000000e+00     0.000000e+00   0.000000e+00     -1.219343e+02   \n",
              "25%    1.000000e+00     1.000000e+00   1.000000e+00     -7.399151e+01   \n",
              "50%    2.000000e+00     1.000000e+00   1.670000e+00     -7.398138e+01   \n",
              "75%    2.000000e+00     2.000000e+00   3.080000e+00     -7.396610e+01   \n",
              "max    2.000000e+00     9.000000e+00   8.000010e+06      0.000000e+00   \n",
              "\n",
              "       pickup_latitude    RatecodeID  dropoff_longitude  dropoff_latitude  \\\n",
              "count     1.090686e+07  1.090686e+07       1.090686e+07      1.090686e+07   \n",
              "mean      4.011494e+01  1.039350e+00      -7.288659e+01      4.015315e+01   \n",
              "std       5.051022e+00  5.186309e-01       8.900841e+00      4.903456e+00   \n",
              "min       0.000000e+00  1.000000e+00      -1.219335e+02      0.000000e+00   \n",
              "25%       4.073630e+01  1.000000e+00      -7.399107e+01      4.073481e+01   \n",
              "50%       4.075369e+01  1.000000e+00      -7.397942e+01      4.075413e+01   \n",
              "75%       4.076808e+01  1.000000e+00      -7.396196e+01      4.076962e+01   \n",
              "max       6.090876e+01  9.900000e+01       0.000000e+00      6.090876e+01   \n",
              "\n",
              "       payment_type   fare_amount         extra       mta_tax    tip_amount  \\\n",
              "count  1.090686e+07  1.090686e+07  1.090686e+07  1.090686e+07  1.090686e+07   \n",
              "mean   1.347536e+00  1.248693e+01  3.130757e-01  4.976705e-01  1.750663e+00   \n",
              "std    4.910804e-01  3.556400e+01  4.156792e-01  5.046685e-02  2.623546e+00   \n",
              "min    1.000000e+00 -9.576000e+02 -4.261000e+01 -5.000000e-01 -2.208000e+02   \n",
              "25%    1.000000e+00  6.500000e+00  0.000000e+00  5.000000e-01  0.000000e+00   \n",
              "50%    1.000000e+00  9.000000e+00  0.000000e+00  5.000000e-01  1.260000e+00   \n",
              "75%    2.000000e+00  1.400000e+01  5.000000e-01  5.000000e-01  2.320000e+00   \n",
              "max    5.000000e+00  1.112709e+05  6.488700e+02  8.970000e+01  9.981400e+02   \n",
              "\n",
              "       tolls_amount  improvement_surcharge  total_amount  \n",
              "count  1.090686e+07           1.090686e+07  1.090686e+07  \n",
              "mean   2.933453e-01           2.997245e-01  1.564140e+01  \n",
              "std    1.694572e+00           1.232553e-02  3.641280e+01  \n",
              "min   -1.740000e+01          -3.000000e-01 -9.584000e+02  \n",
              "25%    0.000000e+00           3.000000e-01  8.300000e+00  \n",
              "50%    0.000000e+00           3.000000e-01  1.162000e+01  \n",
              "75%    0.000000e+00           3.000000e-01  1.716000e+01  \n",
              "max    9.801500e+02           3.000000e-01  1.112716e+05  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-131c8457-eceb-4dcf-bc67-0abcd346ae2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "      <td>1.090686e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.535024e+00</td>\n",
              "      <td>1.670847e+00</td>\n",
              "      <td>4.648197e+00</td>\n",
              "      <td>-7.281869e+01</td>\n",
              "      <td>4.011494e+01</td>\n",
              "      <td>1.039350e+00</td>\n",
              "      <td>-7.288659e+01</td>\n",
              "      <td>4.015315e+01</td>\n",
              "      <td>1.347536e+00</td>\n",
              "      <td>1.248693e+01</td>\n",
              "      <td>3.130757e-01</td>\n",
              "      <td>4.976705e-01</td>\n",
              "      <td>1.750663e+00</td>\n",
              "      <td>2.933453e-01</td>\n",
              "      <td>2.997245e-01</td>\n",
              "      <td>1.564140e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.987718e-01</td>\n",
              "      <td>1.324891e+00</td>\n",
              "      <td>2.981095e+03</td>\n",
              "      <td>9.168964e+00</td>\n",
              "      <td>5.051022e+00</td>\n",
              "      <td>5.186309e-01</td>\n",
              "      <td>8.900841e+00</td>\n",
              "      <td>4.903456e+00</td>\n",
              "      <td>4.910804e-01</td>\n",
              "      <td>3.556400e+01</td>\n",
              "      <td>4.156792e-01</td>\n",
              "      <td>5.046685e-02</td>\n",
              "      <td>2.623546e+00</td>\n",
              "      <td>1.694572e+00</td>\n",
              "      <td>1.232553e-02</td>\n",
              "      <td>3.641280e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.219343e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-1.219335e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-9.576000e+02</td>\n",
              "      <td>-4.261000e+01</td>\n",
              "      <td>-5.000000e-01</td>\n",
              "      <td>-2.208000e+02</td>\n",
              "      <td>-1.740000e+01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-9.584000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-7.399151e+01</td>\n",
              "      <td>4.073630e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-7.399107e+01</td>\n",
              "      <td>4.073481e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>6.500000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>8.300000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.670000e+00</td>\n",
              "      <td>-7.398138e+01</td>\n",
              "      <td>4.075369e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-7.397942e+01</td>\n",
              "      <td>4.075413e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>1.260000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>1.162000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>3.080000e+00</td>\n",
              "      <td>-7.396610e+01</td>\n",
              "      <td>4.076808e+01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-7.396196e+01</td>\n",
              "      <td>4.076962e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>2.320000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>1.716000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>9.000000e+00</td>\n",
              "      <td>8.000010e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.090876e+01</td>\n",
              "      <td>9.900000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.090876e+01</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>1.112709e+05</td>\n",
              "      <td>6.488700e+02</td>\n",
              "      <td>8.970000e+01</td>\n",
              "      <td>9.981400e+02</td>\n",
              "      <td>9.801500e+02</td>\n",
              "      <td>3.000000e-01</td>\n",
              "      <td>1.112716e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131c8457-eceb-4dcf-bc67-0abcd346ae2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-131c8457-eceb-4dcf-bc67-0abcd346ae2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-131c8457-eceb-4dcf-bc67-0abcd346ae2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a91b81f8-f74a-4aa7-a8f4-2b609b9130d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a91b81f8-f74a-4aa7-a8f4-2b609b9130d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a91b81f8-f74a-4aa7-a8f4-2b609b9130d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"VendorID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856156.119836202,\n        \"min\": 0.4987718454294516,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.5350238354620551,\n          2.0,\n          0.4987718454294516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"passenger_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856155.8187136394,\n        \"min\": 0.0,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          10906858.0,\n          1.670846819496504,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trip_distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4444288.02045176,\n        \"min\": 0.0,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.648196988536942,\n          1.67,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pickup_longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856177.2098793024,\n        \"min\": -121.93428802490234,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -72.81869455769787,\n          -73.98137664794923,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pickup_latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856145.094125099,\n        \"min\": 0.0,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.11494259107597,\n          40.75368881225586,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RatecodeID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856151.345796583,\n        \"min\": 0.5186309161908566,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0393496458833515,\n          99.0,\n          0.5186309161908566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dropoff_longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856177.2264798903,\n        \"min\": -121.93348693847656,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -72.88659117441934,\n          -73.97942352294923,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dropoff_latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856145.0996241462,\n        \"min\": 0.0,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          40.15315229928887,\n          40.75413131713867,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"payment_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856156.0286792056,\n        \"min\": 0.4910804463944721,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10906858.0,\n          1.3475360181639846,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fare_amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3850778.4400458434,\n        \"min\": -957.6,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          12.486929470430434,\n          9.0,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extra\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856125.950659827,\n        \"min\": -42.61,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          10906858.0,\n          0.3130756896257384,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mta_tax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856152.018019499,\n        \"min\": -0.5,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10906858.0,\n          0.4976704592651706,\n          89.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tip_amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856116.9809983047,\n        \"min\": -220.8,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.750663115812088,\n          1.26,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tolls_amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856107.9153344645,\n        \"min\": -17.4,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10906858.0,\n          0.29334526221942225,\n          980.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"improvement_surcharge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3856156.5654016095,\n        \"min\": -0.3,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2997244605183268,\n          0.3,\n          0.012325533736153218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3850777.851592487,\n        \"min\": -958.4,\n        \"max\": 10906858.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          15.64139524783391,\n          11.62,\n          10906858.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h23tK9LoEubF"
      },
      "source": [
        "Gives summary statistics (like mean, min, max) for numeric columns — useful for spotting outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9zqMReZ8x2D",
        "outputId": "de24556c-c300-4b37-abc8-fcbdf5c0224a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10906858 entries, 0 to 10906857\n",
            "Data columns (total 19 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   VendorID               int64  \n",
            " 1   tpep_pickup_datetime   object \n",
            " 2   tpep_dropoff_datetime  object \n",
            " 3   passenger_count        int64  \n",
            " 4   trip_distance          float64\n",
            " 5   pickup_longitude       float64\n",
            " 6   pickup_latitude        float64\n",
            " 7   RatecodeID             int64  \n",
            " 8   store_and_fwd_flag     object \n",
            " 9   dropoff_longitude      float64\n",
            " 10  dropoff_latitude       float64\n",
            " 11  payment_type           int64  \n",
            " 12  fare_amount            float64\n",
            " 13  extra                  float64\n",
            " 14  mta_tax                float64\n",
            " 15  tip_amount             float64\n",
            " 16  tolls_amount           float64\n",
            " 17  improvement_surcharge  float64\n",
            " 18  total_amount           float64\n",
            "dtypes: float64(12), int64(4), object(3)\n",
            "memory usage: 1.5+ GB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuFgnyHhD5mV"
      },
      "source": [
        "Gives a summary of the dataset: columns, data types, and how many missing values there are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tg_Lu71dDszy"
      },
      "outputs": [],
      "source": [
        "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
        "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMHVskOlFKFO"
      },
      "source": [
        "Converts the pickup and dropoff time columns from string to proper datetime format for later time-based operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zKbdw8chD0EE"
      },
      "outputs": [],
      "source": [
        "# Calculate trip duration in minutes\n",
        "df['trip_duration_minutes'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bnkDhDtFcpK"
      },
      "source": [
        "Creates a new column trip_duration in minutes, by subtracting pickup time from dropoff time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hzOGCOSVD-zw"
      },
      "outputs": [],
      "source": [
        "df.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgiZyVRAFiD6"
      },
      "source": [
        "Removes trips where duration is zero or negative, which are likely errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8iTE-NLqEShB"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "df['store_and_fwd_flag'] = encoder.fit_transform(df['store_and_fwd_flag'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQD3pdWGGFQM"
      },
      "source": [
        "Converts the text flag Y/N to numbers 0 and 1 using LabelEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "I8mnZThMGqi2",
        "outputId": "5cfba377-b146-4b19-f941-0f5ec7d32671"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          VendorID  passenger_count  trip_distance  pickup_longitude  \\\n",
              "0                2                2           1.10        -73.990372   \n",
              "1                2                5           4.90        -73.980782   \n",
              "2                2                1          10.54        -73.984550   \n",
              "3                2                1           4.75        -73.993469   \n",
              "4                2                3           1.76        -73.960625   \n",
              "...            ...              ...            ...               ...   \n",
              "10906853         2                1           2.20        -74.003578   \n",
              "10906854         1                1           0.00        -73.945488   \n",
              "10906855         1                3           1.40        -73.994240   \n",
              "10906856         1                1           2.10        -73.948067   \n",
              "10906857         1                3           0.00        -73.960938   \n",
              "\n",
              "          pickup_latitude  RatecodeID  store_and_fwd_flag  dropoff_longitude  \\\n",
              "0               40.734695           1                   0         -73.981842   \n",
              "1               40.729912           1                   0         -73.944473   \n",
              "2               40.679565           1                   0         -73.950272   \n",
              "3               40.718990           1                   0         -73.962242   \n",
              "4               40.781330           1                   0         -73.977264   \n",
              "...                   ...         ...                 ...                ...   \n",
              "10906853        40.751011           1                   0         -73.982651   \n",
              "10906854        40.751530           1                   0         -73.945457   \n",
              "10906855        40.766586           1                   0         -73.984428   \n",
              "10906856        40.776531           1                   0         -73.978188   \n",
              "10906857        40.758595           2                   0         -73.961006   \n",
              "\n",
              "          dropoff_latitude  payment_type  fare_amount  extra  mta_tax  \\\n",
              "0                40.732407             2          7.5    0.5      0.5   \n",
              "1                40.716679             1         18.0    0.5      0.5   \n",
              "2                40.788925             1         33.0    0.5      0.5   \n",
              "3                40.657333             2         16.5    0.0      0.5   \n",
              "4                40.758514             2          8.0    0.0      0.5   \n",
              "...                    ...           ...          ...    ...      ...   \n",
              "10906853         40.767509             2          8.5    0.5      0.5   \n",
              "10906854         40.751530             2          2.5    0.5      0.5   \n",
              "10906855         40.753922             2          7.5    0.5      0.5   \n",
              "10906856         40.777435             1         11.5    0.0      0.5   \n",
              "10906857         40.758583             2         52.0    0.0      0.5   \n",
              "\n",
              "          tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
              "0               0.00          0.00                    0.3          8.80   \n",
              "1               0.00          0.00                    0.3         19.30   \n",
              "2               0.00          0.00                    0.3         34.30   \n",
              "3               0.00          0.00                    0.3         17.30   \n",
              "4               0.00          0.00                    0.3          8.80   \n",
              "...              ...           ...                    ...           ...   \n",
              "10906853        0.00          0.00                    0.3          9.80   \n",
              "10906854        0.00          0.00                    0.3          3.80   \n",
              "10906855        0.00          0.00                    0.3          8.80   \n",
              "10906856        2.45          0.00                    0.3         14.75   \n",
              "10906857        0.00          5.54                    0.3         58.34   \n",
              "\n",
              "          trip_duration_minutes  \n",
              "0                      0.000000  \n",
              "1                      0.000000  \n",
              "2                      0.000000  \n",
              "3                      0.000000  \n",
              "4                      0.000000  \n",
              "...                         ...  \n",
              "10906853               7.766667  \n",
              "10906854               0.183333  \n",
              "10906855          107433.066667  \n",
              "10906856          119912.700000  \n",
              "10906857               0.250000  \n",
              "\n",
              "[10906858 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b22e6916-de23-4c6c-890e-ac98dfcd0998\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>trip_duration_minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>-73.990372</td>\n",
              "      <td>40.734695</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.981842</td>\n",
              "      <td>40.732407</td>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4.90</td>\n",
              "      <td>-73.980782</td>\n",
              "      <td>40.729912</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.944473</td>\n",
              "      <td>40.716679</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>19.30</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>10.54</td>\n",
              "      <td>-73.984550</td>\n",
              "      <td>40.679565</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.950272</td>\n",
              "      <td>40.788925</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>34.30</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4.75</td>\n",
              "      <td>-73.993469</td>\n",
              "      <td>40.718990</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.962242</td>\n",
              "      <td>40.657333</td>\n",
              "      <td>2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>17.30</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1.76</td>\n",
              "      <td>-73.960625</td>\n",
              "      <td>40.781330</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.977264</td>\n",
              "      <td>40.758514</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906853</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.20</td>\n",
              "      <td>-74.003578</td>\n",
              "      <td>40.751011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.982651</td>\n",
              "      <td>40.767509</td>\n",
              "      <td>2</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>9.80</td>\n",
              "      <td>7.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906854</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-73.945488</td>\n",
              "      <td>40.751530</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.945457</td>\n",
              "      <td>40.751530</td>\n",
              "      <td>2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.80</td>\n",
              "      <td>0.183333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906855</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1.40</td>\n",
              "      <td>-73.994240</td>\n",
              "      <td>40.766586</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.984428</td>\n",
              "      <td>40.753922</td>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "      <td>107433.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906856</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.10</td>\n",
              "      <td>-73.948067</td>\n",
              "      <td>40.776531</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.978188</td>\n",
              "      <td>40.777435</td>\n",
              "      <td>1</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.3</td>\n",
              "      <td>14.75</td>\n",
              "      <td>119912.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906857</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-73.960938</td>\n",
              "      <td>40.758595</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.961006</td>\n",
              "      <td>40.758583</td>\n",
              "      <td>2</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.54</td>\n",
              "      <td>0.3</td>\n",
              "      <td>58.34</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10906858 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b22e6916-de23-4c6c-890e-ac98dfcd0998')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b22e6916-de23-4c6c-890e-ac98dfcd0998 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b22e6916-de23-4c6c-890e-ac98dfcd0998');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dd0d0ffa-9e8a-400d-a2e1-96803f6407ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd0d0ffa-9e8a-400d-a2e1-96803f6407ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dd0d0ffa-9e8a-400d-a2e1-96803f6407ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBmXj0Nr8XHY"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHTNTFRxH94I"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "df.dropna(inplace=True) removes all rows in the dataframe df that contain any missing (NaN) values.\n",
        "\n",
        "df.drop_duplicates(inplace=True) removes all duplicate rows in df so that each row is unique.\n",
        "\n",
        "inplace=True means these changes happen directly to df without creating a new copy.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Cleaning data by removing missing and duplicate entries helps ensure the model trains on accurate and consistent data, preventing bias or errors caused by incomplete or repeated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrnpPIzi8-mt"
      },
      "outputs": [],
      "source": [
        "df_subset = df.sample(n = 500000, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqjELgPIAsb"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Randomly selects 500,000 rows from the dataframe df and stores them in a new dataframe df_subset.\n",
        "\n",
        "random_state=42 ensures the same 500,000 rows are chosen every time this runs (reproducibility).\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Sampling a subset makes it feasible to work with large datasets by reducing size for faster training and testing, while still maintaining a representative sample of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7atI6yh_Fl_"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB0NrZJHAxQz"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_subset, hue='total_amount')\n",
        "plt.savefig('subset_pairplot.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c-0dxylIoxn"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates a pairplot (scatterplot matrix) of the dataframe subset df_subset. Each pair of numeric variables is plotted against each other.\n",
        "\n",
        "The points are colored by the value of the total_amount column (hue='total_amount'), helping to see how this variable relates to others visually.\n",
        "\n",
        "Saves the plot image as 'subset_pairplot.png'.\n",
        "\n",
        "Displays the plot with plt.show().\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Pairplots help visualize relationships and correlations between multiple numeric features at once. Coloring by a target or important feature like total_amount helps spot trends or clusters relevant to modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPVtOT6d9DHx"
      },
      "outputs": [],
      "source": [
        "numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "n_cols = 3\n",
        "n_rows = (len(numeric_columns) + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, column in enumerate(numeric_columns):\n",
        "    sns.histplot(df_subset[column], kde=True, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {column}')\n",
        "\n",
        "if len(numeric_columns) < len(axes):\n",
        "    for j in range(len(numeric_columns), len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('numeric_columns_distribution.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Ps5a4wIuij"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Finds all numeric columns in the dataframe df.\n",
        "\n",
        "Sets up a grid of subplots with 3 columns and enough rows to fit all numeric columns.\n",
        "\n",
        "For each numeric column, plots a histogram with a Kernel Density Estimate (KDE) overlay on its respective subplot, using data from df_subset.\n",
        "\n",
        "Hides any extra subplot axes if there are fewer numeric columns than grid spots.\n",
        "\n",
        "Adjusts subplot layout, saves the figure as 'numeric_columns_distribution.png', and displays it.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Visualizing the distribution of numeric features helps understand their ranges, skewness, and presence of outliers, guiding feature engineering and model selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFfXMsjDAwKv"
      },
      "outputs": [],
      "source": [
        "n_cols = 2\n",
        "n_rows = (len(numeric_columns) + n_cols - 1) // n_cols\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, column in enumerate(numeric_columns):\n",
        "    sns.boxplot(x=df[column], ax=axes[i])\n",
        "    axes[i].set_title(f'Box Plot of {column}')\n",
        "\n",
        "if len(numeric_columns) < len(axes):\n",
        "    for j in range(len(numeric_columns), len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('numeric_columns_boxplots.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpZHK0b0I0iO"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Sets up a grid of subplots with 2 columns and enough rows for all numeric columns.\n",
        "\n",
        "For each numeric column, creates a box plot in its subplot using the full dataframe df (note: not df_subset).\n",
        "\n",
        "Hides extra subplot axes if there are fewer columns than grid spaces.\n",
        "\n",
        "Adjusts layout, saves the figure as 'numeric_columns_boxplots.png', and displays it.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Box plots highlight median, spread, and potential outliers of numeric features, crucial for detecting anomalies and understanding data variability before modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnDwmG2Mfu_o"
      },
      "outputs": [],
      "source": [
        "corr = df.corr()\n",
        "\n",
        "corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu0iuKzMJc73"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Calculates the correlation matrix for all numeric columns in the dataframe df.\n",
        "\n",
        "The matrix corr contains correlation coefficients (values between -1 and 1) that quantify the linear relationship between each pair of features.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Understanding feature correlations helps identify which variables are strongly related or redundant, guiding feature selection and preventing multicollinearity issues in models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wr-g9HLj9bX"
      },
      "outputs": [],
      "source": [
        "mask = np.triu(np.ones_like(corr, dtype=bool))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBBX7dRIJbVJ"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates a boolean mask for the upper triangle of the correlation matrix corr.\n",
        "\n",
        "np.ones_like(corr, dtype=bool) creates a matrix of True values the same shape as corr.\n",
        "\n",
        "np.triu(...) keeps only the upper triangle part True and sets the rest to False.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "When visualizing a symmetric matrix like correlations, masking the upper triangle avoids redundant information and makes the heatmap cleaner and easier to read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s63jli07kEfX"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCIjQxLuJWC0"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Sets up a figure and axes for plotting a heatmap of the correlation matrix.\n",
        "\n",
        "Uses a diverging color palette from seaborn for clear visualization of positive vs negative correlations.\n",
        "\n",
        "Applies the mask to hide the upper triangle of the matrix.\n",
        "\n",
        "Limits the max value shown on the color scale to 0.3 for contrast.\n",
        "\n",
        "Adds grid lines (linewidths=.5), centers the color scale at zero, and formats the color bar to be smaller (shrink=.5).\n",
        "\n",
        "Displays the heatmap.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Heatmaps offer an intuitive, visual way to inspect complex correlation structures quickly, helping identify feature relationships relevant for modeling decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXvs_gZuRUmu"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcOl8OQUTx97"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpYa0zIXJohm"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Imports two feature scaling classes from scikit-learn’s preprocessing module:\n",
        "\n",
        "MinMaxScaler: Scales features to a specified range, usually 0 to 1, by subtracting the minimum and dividing by the feature range.\n",
        "\n",
        "StandardScaler: Standardizes features by removing the mean and scaling to unit variance (z-score normalization).\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Feature scaling ensures numeric variables are on comparable scales, which improves model convergence and performance, especially for algorithms sensitive to feature magnitude (like gradient descent, SVM, or KNN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1IVvqdtRzh2"
      },
      "outputs": [],
      "source": [
        "# Columns to normalize with Min-Max Scaling\n",
        "min_max_columns = [\n",
        "    \"passenger_count\", \"trip_distance\", \"extra\", \"mta_tax\",\n",
        "    \"tolls_amount\", \"improvement_surcharge\", \"congestion_surcharge\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLh2Yy_9Geaq"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Selects a subset of columns from the DataFrame.\n",
        "\n",
        "Keeps only the columns needed for modeling.\n",
        "\n",
        "Removes columns like raw timestamps which are no longer needed.\n",
        "\n",
        "📌 Why this matters:\n",
        "This prepares the dataset for training. You only keep features that:\n",
        "\n",
        "Are numeric or encoded\n",
        "\n",
        "Help predict the fare\n",
        "\n",
        "Don’t introduce noise or unnecessary information\n",
        "\n",
        "This step is called feature selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh7DiOioTqXK"
      },
      "outputs": [],
      "source": [
        "# Columns to normalize with Standardization\n",
        "z_score_columns = [\n",
        "    \"fare_amount\", \"tip_amount\", \"total_amount\", \"trip_duration_minutes\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM-Tjtx_KFkS"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Defines a list of column names (z_score_columns) from the dataframe that will be normalized using Z-score standardization. These columns relate to monetary amounts and trip duration.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Selecting specific columns ensures you only scale relevant continuous numerical features, avoiding unintended changes to categorical or already scaled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwbyUHVDTsWx"
      },
      "outputs": [],
      "source": [
        "# Initialize scalers\n",
        "min_max_scaler = MinMaxScaler()\n",
        "z_score_scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BGqpvO3KKt_"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates instances of two scaler objects:\n",
        "\n",
        "min_max_scaler for scaling features to a 0-1 range.\n",
        "\n",
        "z_score_scaler for standardizing features to have mean 0 and standard deviation 1.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Initializing scalers prepares them for fitting and transforming your data, enabling consistent scaling procedures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4BF0vTaTuC2"
      },
      "outputs": [],
      "source": [
        "# Normalize using Min-Max Scaling\n",
        "df_subset[min_max_columns] = min_max_scaler.fit_transform(df_subset[min_max_columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvQBm96JKPS_"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Applies Min-Max scaling to the columns listed in min_max_columns of df_subset.\n",
        "\n",
        ".fit_transform() fits the scaler to the data (calculates min and max) and transforms the data accordingly.\n",
        "\n",
        "The scaled values replace the original values in df_subset.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Min-Max scaling compresses feature values into the [0,1] range, which is important for models sensitive to scale and for preserving the relative distribution shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fqr0Ju1U6mk"
      },
      "outputs": [],
      "source": [
        "# Normalize using Z-Score Standardization\n",
        "df_subset[z_score_columns] = z_score_scaler.fit_transform(df_subset[z_score_columns])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDmEoQ0IKdB4"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Applies Z-score standardization to the specified columns in df_subset.\n",
        "\n",
        "Each feature is transformed to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "The transformed values overwrite the original columns.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Standardization centers features and scales them to unit variance, which helps many ML algorithms converge faster and perform better, especially those assuming normally distributed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJxh-KcYU8eO"
      },
      "outputs": [],
      "source": [
        "df_subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gppJp77vKl2w"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Displays the contents of the df_subset dataframe in a notebook or interactive environment like Google Colab or Jupyter.\n",
        "\n",
        "It shows a preview of the data: typically the first few rows and columns by default (similar to calling print(df_subset.head())).\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Quickly checking df_subset allows you to visually confirm that preprocessing steps (like cleaning, sampling, and scaling) were applied correctly. It's a simple yet powerful way to debug and explore your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8x5mi44lcwl"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq-gGCtRlb9w"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChsyKEwjG8_O"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Imports the function used to split your dataset into training and testing sets.\n",
        "\n",
        "📌 Why it matters:\n",
        "You must test your model on new data it hasn’t seen — this avoids overfitting and gives a better measure of how well your model generalizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h1oQwhJeDwM"
      },
      "outputs": [],
      "source": [
        "x = df_subset.iloc[:, 8:10]\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BO4UZxlLFDy"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Selects all rows (:) and only the columns at index positions 8 and 9 (since Python slicing is exclusive of the end index) from df_subset.\n",
        "\n",
        "Stores this slice of the dataframe in a new variable x.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Narrowing down specific feature columns prepares the data for modeling. This step isolates the input features you want to use (e.g., perhaps pickup/dropoff coordinates or time-related fields)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui_VyMa6VU9i"
      },
      "outputs": [],
      "source": [
        "y = df_subset['total_amount']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6gkyrcjHQzl"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Splits the dataset into:\n",
        "\n",
        "80% training data (X_train, y_train)\n",
        "\n",
        "20% testing data (X_test, y_test)\n",
        "\n",
        "random_state=42 makes the split reproducible (same split every time you run it).\n",
        "\n",
        "📌 Why this is critical:\n",
        "You train your model on the training data, and test it on unseen test data to measure its real-world performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aj87tgYcGSf"
      },
      "outputs": [],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5jxMewxLHkp"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Displays the contents of the variable x_test (if it has already been defined) in an interactive environment like Google Colab or Jupyter Notebook.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Viewing x_test lets you inspect your test features to ensure that the right data was split or transformed correctly. This step is essential for validating your model input before making predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ7mz3tnX-6g"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4POtmQnZR2O"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd4SRd_CVVbK"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Imports the LinearRegression model from sklearn.linear_model.\n",
        "\n",
        "Imports common regression evaluation metrics:\n",
        "\n",
        "mean_squared_error\n",
        "\n",
        "mean_absolute_error\n",
        "\n",
        "root_mean_squared_error\n",
        "\n",
        "r2_score\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "These tools are essential for training a linear regression model and evaluating its performance using standard error and accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnBBI1xnZO2Q"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpuBbOcVVRC9"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates an instance of the LinearRegression model and stores it in the variable lr.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Initializing the model object is the first step before training (fitting) it to your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOPqDXneb-mu"
      },
      "outputs": [],
      "source": [
        "lr.fit(x_train, y_train)\n",
        "\n",
        "y_pred_test_lr = lr.predict(x_test)\n",
        "y_pred_train_lr = lr.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7GpmeMBVHxt"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "lr.fit(x_train, y_train) trains the linear regression model on the training data.\n",
        "\n",
        "y_pred_test_lr stores predictions made on the test data.\n",
        "\n",
        "y_pred_train_lr stores predictions made on the training data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Model fitting learns the best-fitting line for your data. Generating predictions for both training and test sets allows you to evaluate performance and check for overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WMfYOsPXPeJ"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with Linear regression is {mean_squared_error(y_pred_test_lr, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with Linear regression is {mean_absolute_error(y_pred_test_lr, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with Linear regression is {root_mean_squared_error(y_pred_test_lr, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with Linear regression is {r2_score(y_pred_test_lr, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRFqqHfV3Cbp"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_lr_test = mean_squared_error(y_pred_test_lr, y_test)\n",
        "Mean_Squared_Error_lr_train = mean_squared_error(y_pred_train_lr, y_train)\n",
        "Mean_Absolute_Error_lr_test = mean_absolute_error(y_pred_test_lr, y_test)\n",
        "Mean_Absolute_Error_lr_train = mean_absolute_error(y_pred_train_lr, y_train)\n",
        "Root_Mean_Squared_Error_lr_test = root_mean_squared_error(y_pred_test_lr, y_test)\n",
        "Root_Mean_Squared_Error_lr_train = root_mean_squared_error(y_pred_train_lr, y_train)\n",
        "R2_Score_Test_data = r2_score(y_pred_test_lr, y_test)\n",
        "R2_Score_train_data = r2_score(y_pred_train_lr, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpA0kaJmU_tC"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Prints the following evaluation metrics on the test data:\n",
        "\n",
        "MSE (Mean Squared Error)\n",
        "\n",
        "MAE (Mean Absolute Error)\n",
        "\n",
        "RMSE (Root Mean Squared Error)\n",
        "\n",
        "R² Score (explained variance)\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "These metrics help quantify how well the model performs on unseen data. Lower errors and higher R² scores indicate better predictive power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTeaqldSZIRe"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with Linear regression is {mean_squared_error(y_pred_train_lr, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with Linear regression is {mean_absolute_error(y_pred_train_lr, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with Linear regression is {root_mean_squared_error(y_pred_train_lr, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with Linear regression is {r2_score(y_pred_train_lr, y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04yelDQ8Uzd2"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Prints the same set of evaluation metrics, but for the training data instead of test data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Comparing training and test performance reveals if the model is overfitting (too good on train, bad on test) or underfitting (bad on both). A balanced performance suggests good generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2H7qzoecCFN"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot of actual values\n",
        "ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_test, color='blue', label='Actual')\n",
        "\n",
        "# Predicted values\n",
        "ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_pred_test_lr, color='red', label='Predicted')\n",
        "\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Total Amount')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAE4zNBHUsm1"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates a 3D scatter plot showing the relationship between the two features used in x_test and the actual (y_test) vs predicted values (y_pred_test_lr).\n",
        "\n",
        "Blue points show actual values; red points show model predictions.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "3D visualization helps you intuitively see how closely the model’s predictions align with the actual outcomes, especially when working with two input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52GQBgHRVnwy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "coefs = pd.DataFrame({'Feature': x.columns, 'Coefficient': lr.coef_})\n",
        "coefs = coefs.sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(coefs['Feature'], coefs['Coefficient'], color='green')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance in Linear Regression')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h86ggaNUqCD"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Extracts the learned coefficients from the linear regression model and pairs them with the feature names.\n",
        "\n",
        "Sorts them by importance and plots a horizontal bar chart showing each feature’s contribution (positive or negative) to the prediction.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Coefficients in linear regression indicate how strongly each feature influences the target. Visualizing them reveals which features are most impactful and in which direction (positive or negative influence)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocWbWkWbZnW1"
      },
      "source": [
        "# Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg61LGRhW1U0"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfWaJt-vWQ5g"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Imports the Ridge regression model from sklearn.linear_model.\n",
        "\n",
        "Ridge regression is a type of regularized linear regression that adds a penalty term to reduce overfitting.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Ridge regression improves model generalization by penalizing large coefficients, making it especially useful when features are correlated or when the model overfits the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou8R3z9Gau8J"
      },
      "outputs": [],
      "source": [
        "ridge_reg = Ridge()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbmLmZqLWUck"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates an instance of the Ridge regression model using default parameters.\n",
        "\n",
        "The model is stored in the variable ridge_reg.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Initializing the model is the first step before training it. This version of Ridge will use L2 regularization with a default alpha (regularization strength)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3h3HJG-a9cn"
      },
      "outputs": [],
      "source": [
        "ridge_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred_train_ridge = ridge_reg.predict(x_train)\n",
        "y_pred_test_ridge = ridge_reg.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiCc18KCWbSv"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Fits the Ridge regression model on the training data.\n",
        "\n",
        "Generates predictions on both the training set (y_pred_train_ridge) and the test set (y_pred_test_ridge).\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Fitting allows the model to learn patterns from training data.\n",
        "\n",
        "Predicting on both train and test sets helps evaluate how well the model has learned and whether it's overfitting or generalizing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLUlH-Tdcbth"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with Ridge regression is {mean_squared_error(y_pred_test_ridge, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with Ridge regression is {mean_absolute_error(y_pred_test_ridge, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with Ridge regression is {root_mean_squared_error(y_pred_test_ridge, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with Ridge regression is {r2_score(y_pred_test_ridge, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DZ8KLJKwMM9"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_ridge_test = mean_squared_error(y_pred_test_ridge, y_test)\n",
        "Mean_Absolute_Error_ridge_test = mean_absolute_error(y_pred_test_ridge, y_test)\n",
        "Root_Mean_Squared_Error_ridge_test = root_mean_squared_error(y_pred_test_ridge, y_test)\n",
        "R2_Score_Test_data_ridge = r2_score(y_pred_test_ridge, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaAenD9kWc9y"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Calculates and prints performance metrics for Ridge regression on the test data:\n",
        "\n",
        "MSE (Mean Squared Error)\n",
        "\n",
        "MAE (Mean Absolute Error)\n",
        "\n",
        "RMSE (Root Mean Squared Error)\n",
        "\n",
        "R² Score\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "These metrics show how well the Ridge model performs on unseen data, measuring both average error and the percentage of variance explained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpoPcaakcmrv"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with Ridge regression is {mean_squared_error(y_pred_train_ridge, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with Ridge regression is {mean_absolute_error(y_pred_train_ridge, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with Ridge regression is {root_mean_squared_error(y_pred_train_ridge, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with Ridge regression is {r2_score(y_pred_train_ridge, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRjoLXq6wuls"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_ridge_train = mean_squared_error(y_pred_train_ridge, y_train)\n",
        "Mean_Absolute_Error_ridge_train = mean_absolute_error(y_pred_train_ridge, y_train)\n",
        "Root_Mean_Squared_Error_ridge_train = root_mean_squared_error(y_pred_train_ridge, y_train)\n",
        "R2_Score_train_data_ridge = r2_score(y_pred_train_ridge, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3g8jq-zWiW6"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Prints the same evaluation metrics, but for the training data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Comparing training vs. testing scores helps detect overfitting or underfitting. A smaller gap between them usually indicates better generalization, especially with regularization like Ridge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPPxU9cDdtjZ"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot of actual values\n",
        "ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_test, color='blue', label='Actual')\n",
        "\n",
        "# Predicted values\n",
        "ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_pred_test_ridge, color='red', label='Predicted')\n",
        "\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Total Amount')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qGpQ6xSWnMc"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates a 3D scatter plot comparing the actual vs. predicted values for the Ridge model using the two features from x_test.\n",
        "\n",
        "Blue points are real values, red points are predictions.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Visual comparison in 3D makes it easy to see how closely predictions align with actual data, especially helpful when using two input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqMeMsUzdtja"
      },
      "outputs": [],
      "source": [
        "coefs = pd.DataFrame({'Feature': x.columns, 'Coefficient': ridge_reg.coef_})\n",
        "coefs = coefs.sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(coefs['Feature'], coefs['Coefficient'], color='green')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance in Linear Regression')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIdmN10eWvIx"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Extracts and visualizes the feature coefficients from the Ridge regression model.\n",
        "\n",
        "Displays them as a horizontal bar chart sorted by their importance (absolute value of the coefficients).\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Ridge regression shrinks the coefficients to reduce model complexity. Visualizing them helps understand which features are still influential after regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaKHJ2Eieb1m"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEhmOrJWd3nY"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2O6GyxAekFD"
      },
      "outputs": [],
      "source": [
        "lasso_reg = Lasso(alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42TZIsYsemli"
      },
      "outputs": [],
      "source": [
        "lasso_reg.fit(x_train, y_train)\n",
        "\n",
        "y_pred_train_lasso = lasso_reg.predict(x_train)\n",
        "y_pred_test_lasso = lasso_reg.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7Ahn96ie6nL"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with Lasso regression is {mean_squared_error(y_pred_test_lasso, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with Lasso regression is {mean_absolute_error(y_pred_test_lasso, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with Lasso regression is {root_mean_squared_error(y_pred_test_lasso, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with Lasso regression is {r2_score(y_pred_test_lasso, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtRk8-eYxncP"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_lasso_test = mean_squared_error(y_pred_test_lasso, y_test)\n",
        "Mean_Absolute_Error_lasso_test = mean_absolute_error(y_pred_test_lasso, y_test)\n",
        "Root_Mean_Squared_Error_lasso_test = root_mean_squared_error(y_pred_test_lasso, y_test)\n",
        "R2_Score_Test_data_lasso = r2_score(y_pred_test_lasso, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY6MwFUrfHrC"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with Ridge regression is {mean_squared_error(y_pred_train_lasso, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with Ridge regression is {mean_absolute_error(y_pred_train_lasso, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with Ridge regression is {root_mean_squared_error(y_pred_train_lasso, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with Ridge regression is {r2_score(y_pred_train_lasso, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDXOmyzFyLuF"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_lasso_train = mean_squared_error(y_pred_train_lasso, y_train)\n",
        "Mean_Absolute_Error_lasso_train = mean_absolute_error(y_pred_train_lasso, y_train)\n",
        "Root_Mean_Squared_Error_lasso_train = root_mean_squared_error(y_pred_train_lasso, y_train)\n",
        "R2_Score_train_data_lasso = r2_score(y_pred_train_lasso, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIgWwHvBfnYN"
      },
      "outputs": [],
      "source": [
        "# Check which features were eliminated\n",
        "print(f\"Remaining features: {sum(lasso_reg.coef_ != 0)}\")\n",
        "print(f\"Eliminated features: {sum(lasso_reg.coef_ == 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcl67PxiX3fz"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Counts and prints how many feature coefficients were retained (non-zero) and how many were set to zero (eliminated) by the Lasso model.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Lasso acts as both a model and a feature selector. Knowing which features were removed helps interpret the model and reduce dimensionality for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Joynema-f1zM"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot of actual values\n",
        "ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_test, color='blue', label='Actual')\n",
        "\n",
        "# Predicted values\n",
        "ax.scatter(x_test.iloc[:, 0], x_test.iloc[:, 1], y_pred_test_lasso, color='red', label='Predicted')\n",
        "\n",
        "ax.set_xlabel('Feature 1')\n",
        "ax.set_ylabel('Feature 2')\n",
        "ax.set_zlabel('Total Amount')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQKhrG0HXw4y"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Visualizes the actual vs. predicted values for the Lasso model in 3D using the two features from x_test.\n",
        "\n",
        "Blue = actual, Red = predicted.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "This visual comparison helps you see the accuracy of the Lasso model and how predictions follow the true target distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgBeYRusf-Ij"
      },
      "outputs": [],
      "source": [
        "coefs = pd.DataFrame({'Feature': x.columns, 'Coefficient': lasso_reg.coef_})\n",
        "coefs = coefs.sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(coefs['Feature'], coefs['Coefficient'], color='green')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance in Linear Regression')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4XT6P5tXqOz"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates a bar chart of the Lasso coefficients, showing each feature’s weight after L1 regularization.\n",
        "\n",
        "Sorted by importance.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "This plot shows how Lasso assigns importance — or zero importance — to features. It's a clear visual representation of which features matter most after regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3CEUaAqjBwp"
      },
      "source": [
        "# Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbRFvT7cgGN9"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRCu4LXvObXn"
      },
      "source": [
        "🔍 What it does: PolynomialFeatures is a tool to expand your features into higher-degree polynomial terms (e.g.,\n",
        "�\n",
        "x becomes\n",
        "�\n",
        ",\n",
        "�\n",
        "2\n",
        ",\n",
        "�\n",
        "3\n",
        ",\n",
        "…\n",
        "x,x\n",
        "2\n",
        " ,x\n",
        "3\n",
        " ,…).\n",
        "\n",
        "LinearRegression is the model that fits a linear relationship to the data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Polynomial features allow a linear regression model to fit non-linear relationships. Importing these tools is the first step in building a more flexible model that captures curves in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3ykLJBHjLqX"
      },
      "outputs": [],
      "source": [
        "poly = PolynomialFeatures()\n",
        "\n",
        "x_train_poly = poly.fit_transform(x_train)\n",
        "x_test_poly = poly.fit_transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbcZb1t6Oo2P"
      },
      "source": [
        "🔍 What it does: Initializes a PolynomialFeatures object with default degree 2.\n",
        "\n",
        "fit_transform(x_train) learns the polynomial structure and transforms x_train into new features:\n",
        "�\n",
        ",\n",
        "�\n",
        "2\n",
        ",\n",
        "�\n",
        "1\n",
        "�\n",
        "2\n",
        ",\n",
        "…\n",
        "x,x\n",
        "2\n",
        " ,x\n",
        "1\n",
        "​\n",
        " x\n",
        "2\n",
        "​\n",
        " ,….\n",
        "\n",
        "Applies the same transformation to x_test.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Transforms your simple input features into a richer set that includes interaction terms and powers. This helps a linear model handle non-linear relationships more effectively. Without this step, the model would only capture straight-line trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A96qi-YPlme2"
      },
      "outputs": [],
      "source": [
        "x_train_poly.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6zSKt8lPCrV"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints the dimensions of the transformed x_train_poly matrix, including how many new features were generated.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Understanding the shape confirms how many features were added. It also helps debug if your data transformation went as expected (e.g., from 3 features to 10 after expanding to 2nd degree)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfkY7p9Rl40K"
      },
      "outputs": [],
      "source": [
        "poly_reg = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKlhKhUal40L"
      },
      "outputs": [],
      "source": [
        "poly_reg.fit(x_train_poly, y_train)\n",
        "\n",
        "y_pred_test_poly = poly_reg.predict(x_test_poly)\n",
        "y_pred_train_poly = poly_reg.predict(x_train_poly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOi0kn9JPQcA"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Creates a linear regression model.\n",
        "\n",
        "Fits the model to the polynomial-transformed training data.\n",
        "\n",
        "Predicts on both transformed test and train sets.\n",
        "\n",
        "📌 Why this is critical:\n",
        "The model now learns from the polynomial-expanded features, allowing it to fit curves and complex shapes. Predicting on both train and test sets helps assess performance and overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDd_eiHHl40L"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with Polynomial Linear regression is {mean_squared_error(y_pred_test_poly, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with Polynomial Linear regression is {mean_absolute_error(y_pred_test_poly, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with Polynomial Linear regression is {root_mean_squared_error(y_pred_test_poly, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with Linear Polynomial regression is {r2_score(y_pred_test_poly, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DArCSGGdykxq"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_poly_test = mean_squared_error(y_pred_test_poly, y_test)\n",
        "Mean_Absolute_Error_poly_test = mean_absolute_error(y_pred_test_poly, y_test)\n",
        "Root_Mean_Squared_Error_poly_test = root_mean_squared_error(y_pred_test_poly, y_test)\n",
        "R2_Score_Test_data_poly = r2_score(y_pred_test_poly, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L8WWcWGPWzH"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints four evaluation metrics for test data using polynomial regression:\n",
        "\n",
        "MSE: Average squared prediction error.\n",
        "\n",
        "MAE: Average absolute error.\n",
        "\n",
        "RMSE: Square root of MSE, more interpretable.\n",
        "\n",
        "R² Score: How well the model explains variance in the target.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These metrics give you a complete picture of your model’s performance on unseen data. If these scores are high (especially R²) and errors low, your polynomial model generalizes well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJtVoLsxl40L"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with Linear regression is {mean_squared_error(y_pred_train_lr, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with Linear regression is {mean_absolute_error(y_pred_train_lr, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with Linear regression is {root_mean_squared_error(y_pred_train_lr, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with Linear regression is {r2_score(y_pred_train_lr, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1a5AWjHzDIu"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_poly_train = mean_squared_error(y_pred_train_poly, y_train)\n",
        "Mean_Absolute_Error_poly_train = mean_absolute_error(y_pred_train_poly, y_train)\n",
        "Root_Mean_Squared_Error_poly_train = root_mean_squared_error(y_pred_train_poly, y_train)\n",
        "R2_Score_Test_data_poly_train = r2_score(y_pred_train_poly, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w2Ig_34PakQ"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints the same metrics as above, but for the original linear regression model (before polynomial transformation) on training data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This allows you to compare the basic linear model against the polynomial version. If the polynomial model performs significantly better, it shows your data has non-linear patterns worth capturing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeKrQdy3QphO"
      },
      "source": [
        "# K Nearest Neighbor Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxOq2sz9QjpC"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0idffXZX2Kv"
      },
      "source": [
        "🔍 What it does:\n",
        "Imports the KNeighborsRegressor class from Scikit-learn, which implements KNN for regression tasks.\n",
        "\n",
        "📌 Why this is critical:\n",
        "KNN is a non-parametric, instance-based method. It predicts the target value of a new point by averaging the values of its\n",
        "\n",
        "k nearest neighbors in the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF93UKzmQvip"
      },
      "outputs": [],
      "source": [
        "knn_reg = KNeighborsRegressor()\n",
        "knn_reg.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34YxItKlXywc"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Instantiates a KNN regression model with default parameters (n_neighbors=5).\n",
        "\n",
        "Trains the model by memorizing the training data (no actual fitting, just storing examples).\n",
        "\n",
        "📌 Why this is critical:\n",
        "KNN doesn’t “learn” a function in the traditional sense—it saves the training data and uses it to make predictions at test time by computing distances between points. Simple and effective when features are well-scaled and not too high-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4wRZloaQ0sN"
      },
      "outputs": [],
      "source": [
        "y_pred_test_knn = knn_reg.predict(x_test)\n",
        "y_pred_train_knn = knn_reg.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lOJ0crLXrcV"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Predicts target values for both test and training datasets.\n",
        "\n",
        "For each point, finds the\n",
        "�\n",
        "k nearest neighbors and averages their target values.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Used for evaluating model performance. Predictions on both train and test sets help you measure how well the model memorizes and generalizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w3yNFXqQ5Vu"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with KNN Regression is {mean_squared_error(y_pred_test_knn, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with KNN Regression is {mean_absolute_error(y_pred_test_knn, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with KNN Regression is {root_mean_squared_error(y_pred_test_knn, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with KNN Regression is {r2_score(y_pred_test_knn, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uex5R38znEX"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_knn_test = mean_squared_error(y_pred_test_knn, y_test)\n",
        "Mean_Absolute_Error_knn_test = mean_absolute_error(y_pred_test_knn, y_test)\n",
        "Root_Mean_Squared_Error_knn_test = root_mean_squared_error(y_pred_test_knn, y_test)\n",
        "R2_Score_Test_data_knn = r2_score(y_pred_test_knn, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjdDuBxFXmvY"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints standard performance metrics on the test dataset:\n",
        "\n",
        "MSE: Average squared prediction error.\n",
        "\n",
        "MAE: Average absolute difference from true values.\n",
        "\n",
        "RMSE: Easier-to-interpret version of MSE.\n",
        "\n",
        "R²: Proportion of variance explained by the model.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These metrics help you understand how accurate your predictions are on unseen data. Low errors and high R² indicate good generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW9V9iY1Q-n9"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with KNN Regression is {mean_squared_error(y_pred_train_knn, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with KNN Regression is {mean_absolute_error(y_pred_train_knn, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with KNN Regression is {root_mean_squared_error(y_pred_train_knn, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with KNN Regression is {r2_score(y_pred_train_knn, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt-st9NSz3N_"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_knn_train = mean_squared_error(y_pred_train_knn, y_train)\n",
        "Mean_Absolute_Error_knn_train = mean_absolute_error(y_pred_train_knn, y_train)\n",
        "Root_Mean_Squared_Error_knn_train = root_mean_squared_error(y_pred_train_knn, y_train)\n",
        "R2_Score_train_data_knn = r2_score(y_pred_train_knn, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWpDsFWJXlim"
      },
      "source": [
        "🔍 What it does:\n",
        "Calculates and prints the same evaluation metrics for the training data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Comparison between train and test errors helps you diagnose:\n",
        "\n",
        "Overfitting: Very low train error, high test error.\n",
        "\n",
        "Underfitting: High errors on both.\n",
        "\n",
        "Good generalization: Similar and low errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcOzzgvrTJEQ"
      },
      "source": [
        "# Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYPT4UGuTT2E"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYy1KeoeZX-t"
      },
      "source": [
        "🔍 What it does:\n",
        "Imports the DecisionTreeRegressor class from Scikit-learn.\n",
        "\n",
        "📌 Why this is critical:\n",
        "A Decision Tree Regressor splits your dataset into decision rules based on feature values to predict continuous output. It’s simple yet powerful—especially when your data has clear boundaries or non-linear relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUfmq4mlTbBY"
      },
      "outputs": [],
      "source": [
        "dt_reg = DecisionTreeRegressor()\n",
        "dt_reg.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N63SVheNZUG4"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Instantiates a Decision Tree with default parameters.\n",
        "\n",
        "Fits the model by building a tree of decisions that maps features in x_train to target values in y_train.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Training constructs the actual decision tree by recursively splitting data to minimize prediction error. This step builds the core logic the model uses to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsX2ARE9Ter0"
      },
      "outputs": [],
      "source": [
        "y_pred_test_dt = dt_reg.predict(x_test)\n",
        "y_pred_train_dt = dt_reg.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWbRyxWmZABo"
      },
      "source": [
        "🔍 What it does:\n",
        "Generates predicted values using the trained decision tree for both testing and training sets.\n",
        "\n",
        "📌 Why this is critical:\n",
        "You need these predictions to evaluate how well the model performs on unseen data (test) and on what it has already learned (train)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVXzFjTsTiRX"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with Decision Tree regression is {mean_squared_error(y_pred_test_dt, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with Decision Tree regression is {mean_absolute_error(y_pred_test_dt, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with Decision Tree regression is {root_mean_squared_error(y_pred_test_dt, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with Decision Tree regression is {r2_score(y_pred_test_dt, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh6WHSRy1DNM"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_dt_test = mean_squared_error(y_pred_test_dt, y_test)\n",
        "Mean_Absolute_Error_dt_test = mean_absolute_error(y_pred_test_dt, y_test)\n",
        "Root_Mean_Squared_Error_dt_test = root_mean_squared_error(y_pred_test_dt, y_test)\n",
        "R2_Score_Test_data_dt = r2_score(y_pred_test_dt, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om6bVBOPY69l"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints the performance metrics for the test set.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Decision Trees can easily overfit: they perform perfectly on training data but poorly on test data.\n",
        "\n",
        "These metrics reveal whether the model has generalized well or is too tailored to the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKNi2FWuTluA"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with Decision Tree regression is {mean_squared_error(y_pred_train_dt, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with Decision Tree regression is {mean_absolute_error(y_pred_train_dt, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with Decision Tree regression is {root_mean_squared_error(y_pred_train_dt, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with Decision Tree regression is {r2_score(y_pred_train_dt, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyAPbwCB1aGs"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_dt_train = mean_squared_error(y_pred_train_dt, y_train)\n",
        "Mean_Absolute_Error_dt_train = mean_absolute_error(y_pred_train_dt, y_train)\n",
        "Root_Mean_Squared_Error_dt_train = root_mean_squared_error(y_pred_train_dt, y_train)\n",
        "R2_Score_train_data_dt = r2_score(y_pred_train_dt, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmimJLiaY2fl"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints the same metrics as above, but on the training set.\n",
        "\n",
        "📌 Why this is critical:\n",
        "\n",
        "Very low training error with high test error usually means overfitting.\n",
        "\n",
        "Comparing these values helps you diagnose whether to apply tree pruning or use ensemble methods like Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr_07WrYT0Oe"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(dt_reg, filled=True, feature_names=df.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avbsPPbCY1SY"
      },
      "source": [
        "🔍 What it does:\n",
        "Plots the full decision tree with feature names and decision values.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This gives you insight into how decisions are made—which features and values the tree splits on. It's great for interpretability, especially for small to medium-sized trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls9HZ0SEUR8r"
      },
      "outputs": [],
      "source": [
        "\n",
        "feature_importance = dt_reg.feature_importances_\n",
        "features = df_subset.columns\n",
        "\n",
        "\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=feature_importance[sorted_idx], y=features[sorted_idx], palette=\"viridis\")\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"Feature Importance in Decision Tree\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9AJE2f7YvyF"
      },
      "source": [
        "🔍 What it does:\n",
        "Plots the relative importance of each feature in the decision tree.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This helps you:\n",
        "\n",
        "Identify which features influence predictions the most.\n",
        "\n",
        "Remove unimportant features to reduce complexity or overfitting.\n",
        "\n",
        "Compare models (e.g., how SVM vs. tree treats features)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS_BWrGbVLJd"
      },
      "source": [
        "# SVR(Support Vector Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05fTJ5j-VCyO"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNZgL1j2WLHz"
      },
      "source": [
        "🔍 What it does:\n",
        "Imports the SVR class (Support Vector Regression) from Scikit-learn's support vector machine module.\n",
        "\n",
        "📌 Why this is critical:\n",
        "SVR is a powerful algorithm that fits a regression line (or curve) within a margin of tolerance. It’s great for small- to medium-sized datasets, and works well in high-dimensional spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLe5xMGCVUkA"
      },
      "outputs": [],
      "source": [
        "svr = SVR()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaYNo7HjWGqS"
      },
      "source": [
        "🔍 What it does:\n",
        "Creates an SVR model with default hyperparameters:\n",
        "\n",
        "Kernel: 'rbf' (radial basis function)\n",
        "\n",
        "C (penalty): 1.0\n",
        "\n",
        "Epsilon (tolerance): 0.1\n",
        "\n",
        "📌 Why this is critical:\n",
        "The model is now ready to be trained. Default settings are often a starting point, but performance can be improved significantly by tuning C, epsilon, and kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHJjpDYWVXEJ"
      },
      "outputs": [],
      "source": [
        "svr.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0elG7EAWDbm"
      },
      "source": [
        "🔍 What it does:\n",
        "Fits the SVR model to the training data by finding a regression function that keeps errors within a certain margin (epsilon) as much as possible.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This is the learning step. SVR doesn’t just minimize the error—it tries to balance the error and model complexity, making it less prone to overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37md7k9PVbbB"
      },
      "outputs": [],
      "source": [
        "y_pred_train_svr = svr.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZm1R9dlV_9b"
      },
      "source": [
        "🔍 What it does:\n",
        "Predicts the outputs for the same data the model was trained on.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Used to assess how well the model fits the training set. Important for diagnosing underfitting or overfitting when compared with test performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJqm5UWXVd1s"
      },
      "outputs": [],
      "source": [
        "y_pred_test_svr= svr.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYyCYvBzV-qo"
      },
      "source": [
        "🔍 What it does:\n",
        "Uses the trained SVR model to predict outcomes for unseen test data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Shows how well the model generalizes to new data. Generalization is the goal of all machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGIxDI8qVggt"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with svr is {mean_squared_error(y_pred_test_svr, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with svr is {mean_absolute_error(y_pred_test_svr, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with svr is {root_mean_squared_error(y_pred_test_svr, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with svr is {r2_score(y_pred_test_svr, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EKFk3aV1yvw"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_svr_test = mean_squared_error(y_pred_test_svr, y_test)\n",
        "Mean_Absolute_Error_svr_test = mean_absolute_error(y_pred_test_svr, y_test)\n",
        "Root_Mean_Squared_Error_svr_test = root_mean_squared_error(y_pred_test_svr, y_test)\n",
        "R2_Score_Test_data_svr = r2_score(y_pred_test_svr, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikLSs7QnV2JH"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints common error metrics and the\n",
        "R\n",
        "2\n",
        "  score for the test set.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These values help you measure prediction quality:\n",
        "\n",
        "MSE/MAE/RMSE tell you how far predictions are from actual values.\n",
        "\n",
        "R² indicates how much variance in the target variable is explained by the model. A value close to 1 is ideal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtuWzUQPVl_v"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with svr  is {mean_squared_error(y_pred_train_svr, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with svr  is {mean_absolute_error(y_pred_train_svr, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with svr  is {root_mean_squared_error(y_pred_train_svr, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with svr  is {r2_score(y_pred_train_svr, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfusGB_m2DyA"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_svr_train = mean_squared_error(y_pred_train_svr, y_train)\n",
        "Mean_Absolute_Error_svr_train = mean_absolute_error(y_pred_train_svr, y_train)\n",
        "Root_Mean_Squared_Error_svr_train = root_mean_squared_error(y_pred_train_svr, y_train)\n",
        "R2_Score_Train_data_svr = r2_score(y_pred_train_svr, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POgeREn5VtTr"
      },
      "source": [
        "🔍 What it does:\n",
        "Evaluates the same metrics for the training set.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This comparison helps spot overfitting or underfitting:\n",
        "\n",
        "If train score is very good but test is poor → overfitting.\n",
        "\n",
        "If both scores are low → underfitting.\n",
        "\n",
        "If both are high and similar → good model fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O0DC9Tzb1FQ"
      },
      "source": [
        "# Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th7Uo0pDwQSt"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg-PvGOjUmJ9"
      },
      "source": [
        "🔍 What it does:\n",
        "Imports RandomForestRegressor, an ensemble learning method that builds multiple decision trees and averages their predictions.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Random Forests are robust, powerful, and handle non-linearity well. They often outperform single models and are less prone to overfitting than individual decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4mQZK_DwRdx"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0frQF2LPUjkn"
      },
      "source": [
        "🔍 What it does:\n",
        "Creates a dictionary of settings for GridSearchCV to try:\n",
        "\n",
        "n_estimators: how many trees in the forest.\n",
        "\n",
        "max_depth: how deep each tree can grow.\n",
        "\n",
        "min_samples_split & min_samples_leaf: control how trees split, affecting overfitting.\n",
        "\n",
        "max_features: number of features considered at each split.\n",
        "\n",
        "bootstrap: whether to use bootstrapping for sampling.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Random forests have many hyperparameters, and tuning them is key to balancing bias vs variance and improving generalization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXJ4vA_-wT-t"
      },
      "outputs": [],
      "source": [
        "rfr = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89XvvJhdUWFA"
      },
      "source": [
        "🔍 What it does:\n",
        "Initializes a random forest model with default settings (not yet trained or tuned).\n",
        "\n",
        "📌 Why this is critical:\n",
        "You need a base model to pass into the GridSearchCV. The actual training and tuning happen in the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAqlJ3krwVxW"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(rfr, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtevMrcUOzt"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Uses 3-fold cross-validation to try every combination of param_grid.\n",
        "\n",
        "n_jobs=-1: uses all CPU cores to speed up search.\n",
        "\n",
        "scoring='neg_mean_squared_error': lower MSE = better performance.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This systematically searches for the best configuration of hyperparameters that minimizes error on validation splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UePkLTfwwZl4"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U245SU3XUKSH"
      },
      "source": [
        "🔍 What it does:\n",
        "Trains models on different hyperparameter combinations and evaluates their performance using cross-validation.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This step finds the best-performing model configuration based on training data, avoiding the need for manual trial-and-error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddski3qlwcDs"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgfvrNt4UGxN"
      },
      "source": [
        "🔍 What it does:\n",
        "Outputs the best combination of hyperparameters found during the grid search.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These parameters should be used to retrain the final model. Using default settings afterward (as in line 7) ignores this optimized configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTqVcA9Swd4l"
      },
      "outputs": [],
      "source": [
        "best_rfr = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxMi-bLeUAmK"
      },
      "source": [
        "🔍 What it does:\n",
        "Creates a new Random Forest model with default parameters again.\n",
        "\n",
        "📌 Why this is critical (⚠️ Warning):\n",
        "You should use the best parameters found by GridSearchCV. Right now, you're training a model with default, not optimal, settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNo97jsUwhJf"
      },
      "outputs": [],
      "source": [
        "best_rfr.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4plXdG3qT8w3"
      },
      "source": [
        "🔍 What it does:\n",
        "Fits the random forest model to the training data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "The model now learns patterns from the training set, using multiple decision trees and averaging their predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rK0HlJTwi-h"
      },
      "outputs": [],
      "source": [
        "y_pred_test_rfr= best_rfr.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXe4IfxCT49R"
      },
      "source": [
        "🔍 What it does:\n",
        "Generates predictions on unseen test data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These predictions are used to evaluate how well your trained model performs on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qQ4xpHqwlNQ"
      },
      "outputs": [],
      "source": [
        "y_pred_train_rfr= best_rfr.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lrfs-fhT1K5"
      },
      "source": [
        "🔍 What it does:\n",
        "Makes predictions on the training data the model was trained on.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Used to check for overfitting: if train error is much lower than test error, your model may not generalize well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54oHuxHxwn6E"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with rfr is {mean_squared_error(y_pred_test_rfr, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with rfr is {mean_absolute_error(y_pred_test_rfr, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with rfr is {root_mean_squared_error(y_pred_test_rfr, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with rfr is {r2_score(y_pred_test_rfr, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqY8Vqbh2-ED"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_rfr_test = mean_squared_error(y_pred_test_rfr, y_test)\n",
        "Mean_Absolute_Error_rfr_test = mean_absolute_error(y_pred_test_rfr, y_test)\n",
        "Root_Mean_Squared_Error_rfr_test = root_mean_squared_error(y_pred_test_rfr, y_test)\n",
        "R2_Score_Test_data_rfr = r2_score(y_pred_test_rfr, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlbC119GTudc"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints error metrics and\n",
        "\n",
        "\n",
        "R\n",
        "2\n",
        "  score for test set.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These numbers tell you how well your model generalizes. You want low error values and high R², which means more variance in the target is explained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzhSp7hpwqxj"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with rfr  is {mean_squared_error(y_pred_train_rfr, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with rfr  is {mean_absolute_error(y_pred_train_rfr, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with rfr  is {root_mean_squared_error(y_pred_train_rfr, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with rfr  is {r2_score(y_pred_train_rfr, y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHveuJyd3MgG"
      },
      "outputs": [],
      "source": [
        "Mean_Squared_Error_rfr_train = mean_squared_error(y_pred_train_rfr, y_train)\n",
        "Mean_Absolute_Error_rfr_train = mean_absolute_error(y_pred_train_rfr, y_train)\n",
        "Root_Mean_Squared_Error_rfr_train = root_mean_squared_error(y_pred_train_rfr, y_train)\n",
        "R2_Score_Train_data_rfr = r2_score(y_pred_train_rfr, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO86GnLwTqlK"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints same metrics for the training set.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Comparing with test scores helps detect overfitting. For Random Forests, it's common to have near-perfect training accuracy—but too much of a gap is a red flag."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDSZ_qMmc44O"
      },
      "source": [
        "# MLP regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiDM5Gy_c38I"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtK1ou1oSJwu"
      },
      "source": [
        "🔍 What it does:\n",
        "Imports MLPRegressor, a feedforward neural network model for regression tasks from Scikit-learn.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This model can learn complex non-linear relationships by adjusting multiple layers of neurons—more powerful than linear models, especially with enough data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw30bm91wxrw"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['adam', 'lbfgs', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6AZ_95xSEqK"
      },
      "source": [
        "🔍 What it does:\n",
        "Creates a dictionary of hyperparameters to try for tuning the MLPRegressor:\n",
        "\n",
        "hidden_layer_sizes: different architectures (1 or 2 layers with different neuron counts).\n",
        "\n",
        "activation: function applied to neuron outputs (e.g., ReLU, tanh, logistic).\n",
        "\n",
        "solver: optimization algorithm (e.g., Adam, L-BFGS, SGD).\n",
        "\n",
        "alpha: regularization strength to prevent overfitting.\n",
        "\n",
        "learning_rate: strategy for updating weights.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Hyperparameter tuning is essential for neural networks. The right combination can dramatically improve performance. Without it, the model might underfit or overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyN0_LIhw1Nh"
      },
      "outputs": [],
      "source": [
        "mlp = MLPRegressor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y38MaQ_hR_tD"
      },
      "source": [
        "🔍 What it does:\n",
        "Instantiates a base MLPRegressor model using default parameters.\n",
        "\n",
        "📌 Why this is critical:\n",
        "You need a base model to pass into the GridSearchCV for tuning. This step prepares the model structure but doesn't train it yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrg3a9Q_w2xt"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(mlp, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4cU43ZR3L8"
      },
      "source": [
        "🔍 What it does:\n",
        "\n",
        "Runs grid search over all combinations in param_grid.\n",
        "\n",
        "Uses 3-fold cross-validation to test performance.\n",
        "\n",
        "n_jobs=-1: uses all CPU cores to speed up search.\n",
        "\n",
        "scoring='neg_mean_squared_error': the lower the MSE, the better the model.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This step automates model tuning. It finds the best combination of hyperparameters based on test performance—essential for reliable and accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFxNOD5Jw6ng"
      },
      "outputs": [],
      "source": [
        "print(\"Best parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXLPXArRRuHt"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints the best combination of hyperparameters found by GridSearchCV.\n",
        "\n",
        "📌 Why this is critical:\n",
        "You now know which architecture and settings give the lowest error on validation data. This helps guide how you build the final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPSgCftQw-MY"
      },
      "outputs": [],
      "source": [
        "best_mlp= MLPRegressor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h01soJh1RlN2"
      },
      "source": [
        "🔍 What it does:\n",
        "Creates a new MLPRegressor. Note: You should ideally initialize it with the best_params_ found above.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This step sets up the model that you’ll train and evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zjrcYo3xA-P"
      },
      "outputs": [],
      "source": [
        "best_mlp.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1oCyOaiRMT3"
      },
      "source": [
        "🔍 What it does:\n",
        "Trains the neural network on the training dataset using backpropagation.\n",
        "\n",
        "📌 Why this is critical:\n",
        "This is where the model learns the mapping from input features to the target variable by adjusting internal weights over multiple iterations (epochs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75L4JSrqxBuB"
      },
      "outputs": [],
      "source": [
        "y_pred_test_mlp= best_mlp.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N2SR6O1RIpG"
      },
      "source": [
        "🔍 What it does:\n",
        "Generates predictions on the test dataset using the trained neural network.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Test predictions are used to evaluate how well the model generalizes to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSs3dqFXxDrX"
      },
      "outputs": [],
      "source": [
        "y_pred_train_mlp= best_mlp.predict(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69neLWn5RHDF"
      },
      "source": [
        "🔍 What it does:\n",
        "Generates predictions on the same data the model was trained on.\n",
        "\n",
        "📌 Why this is critical:\n",
        "Used to evaluate overfitting: If training error is low but test error is high, the model is too tailored to the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PYtQl7wxISg"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Test data with mlp is {mean_squared_error(y_pred_test_mlp, y_test)}\")\n",
        "print(f\"The Mean Absolute Error of Test data with mlp is {mean_absolute_error(y_pred_test_mlp, y_test)}\")\n",
        "print(f\"The Root Mean Squared Error of Test data with mlp is {root_mean_squared_error(y_pred_test_mlp, y_test)}\")\n",
        "print(f\"\\nThe R2 Score Test data with mlp is {r2_score(y_pred_test_mlp, y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgVl_2KDQ6g0"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints standard error metrics and\n",
        "R\n",
        "2\n",
        "  score for the test data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "These values tell you how well your neural network performs on unseen data. A good model should have:\n",
        "\n",
        "Low MSE, MAE, RMSE.\n",
        "\n",
        "High\n",
        "R\n",
        "2\n",
        " , ideally close to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lRM8eOtxJC2"
      },
      "outputs": [],
      "source": [
        "print(f\"The Mean Squared Error of Train data with mlp  is {mean_squared_error(y_pred_train_mlp, y_train)}\")\n",
        "print(f\"The Mean Absolute Error of Train data with mlp  is {mean_absolute_error(y_pred_train_mlp, y_train)}\")\n",
        "print(f\"The Root Mean Squared Error of Train data with mlp  is {root_mean_squared_error(y_pred_train_mlp, y_train)}\")\n",
        "print(f\"\\nThe R2 Score Train data with mlp  is {r2_score(y_pred_train_mlp, y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXxSJZtWQxbY"
      },
      "source": [
        "🔍 What it does:\n",
        "Prints the same metrics for training data.\n",
        "\n",
        "📌 Why this is critical:\n",
        "By comparing train vs. test performance, you can identify:\n",
        "\n",
        "Overfitting: Low train error, high test error.\n",
        "\n",
        "Underfitting: High errors on both train and test.\n",
        "\n",
        "Well-fit model: Similar and low errors on both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28ujW54y6Xt5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "metrics = {\n",
        "    \"Model\": [\"Linear\", \"Ridge\", \"Lasso\", \"Polynomial\", \"KNN\", \"Decision Tree\", \"SVR\", \"Random Forest\"],\n",
        "    \"MSE Test\": [\n",
        "        Mean_Squared_Error_lr_test,\n",
        "        Mean_Squared_Error_ridge_test,\n",
        "        Mean_Squared_Error_lasso_test,\n",
        "        Mean_Squared_Error_poly_test,\n",
        "        Mean_Squared_Error_knn_test,\n",
        "        Mean_Squared_Error_dt_test,\n",
        "        Mean_Squared_Error_svr_test,\n",
        "        Mean_Squared_Error_rfr_test\n",
        "    ],\n",
        "    \"MSE Train\": [\n",
        "        Mean_Squared_Error_lr_train,\n",
        "        Mean_Squared_Error_ridge_train,\n",
        "        Mean_Squared_Error_lasso_train,\n",
        "        Mean_Squared_Error_poly_train,\n",
        "        Mean_Squared_Error_knn_train,\n",
        "        Mean_Squared_Error_dt_train,\n",
        "        Mean_Squared_Error_svr_train,\n",
        "        Mean_Squared_Error_rfr_train\n",
        "    ],\n",
        "    \"MAE Test\": [\n",
        "        Mean_Absolute_Error_lr_test,\n",
        "        Mean_Absolute_Error_ridge_test,\n",
        "        Mean_Absolute_Error_lasso_test,\n",
        "        Mean_Absolute_Error_poly_test,\n",
        "        Mean_Absolute_Error_knn_test,\n",
        "        Mean_Absolute_Error_dt_test,\n",
        "        Mean_Absolute_Error_svr_test,\n",
        "        Mean_Absolute_Error_rfr_test\n",
        "    ],\n",
        "    \"MAE Train\": [\n",
        "        Mean_Absolute_Error_lr_train,\n",
        "        Mean_Absolute_Error_ridge_train,\n",
        "        Mean_Absolute_Error_lasso_train,\n",
        "        Mean_Absolute_Error_poly_train,\n",
        "        Mean_Absolute_Error_knn_train,\n",
        "        Mean_Absolute_Error_dt_train,\n",
        "        Mean_Absolute_Error_svr_train,\n",
        "        Mean_Absolute_Error_rfr_train\n",
        "    ],\n",
        "    \"RMSE Test\": [\n",
        "        Root_Mean_Squared_Error_lr_test,\n",
        "        Root_Mean_Squared_Error_ridge_test,\n",
        "        Root_Mean_Squared_Error_lasso_test,\n",
        "        Root_Mean_Squared_Error_poly_test,\n",
        "        Root_Mean_Squared_Error_knn_test,\n",
        "        Root_Mean_Squared_Error_dt_test,\n",
        "        Root_Mean_Squared_Error_svr_test,\n",
        "        Root_Mean_Squared_Error_rfr_test\n",
        "    ],\n",
        "    \"RMSE Train\": [\n",
        "        Root_Mean_Squared_Error_lr_train,\n",
        "        Root_Mean_Squared_Error_ridge_train,\n",
        "        Root_Mean_Squared_Error_lasso_train,\n",
        "        Root_Mean_Squared_Error_poly_train,\n",
        "        Root_Mean_Squared_Error_knn_train,\n",
        "        Root_Mean_Squared_Error_dt_train,\n",
        "        Root_Mean_Squared_Error_svr_train,\n",
        "        Root_Mean_Squared_Error_rfr_train\n",
        "    ],\n",
        "    \"R2 Test\": [\n",
        "        R2_Score_Test_data,\n",
        "        R2_Score_Test_data_ridge,\n",
        "        R2_Score_Test_data_lasso,\n",
        "        R2_Score_Test_data_poly,\n",
        "        R2_Score_Test_data_knn,\n",
        "        R2_Score_Test_data_dt,\n",
        "        R2_Score_Test_data_svr,\n",
        "        R2_Score_Test_data_rfr\n",
        "    ],\n",
        "    \"R2 Train\": [\n",
        "        R2_Score_train_data,\n",
        "        R2_Score_train_data_ridge,\n",
        "        R2_Score_train_data_lasso,\n",
        "        R2_Score_Test_data_poly_train,  # You might want to rename this to \"train\"\n",
        "        R2_Score_train_data_knn,\n",
        "        R2_Score_train_data_dt,\n",
        "        R2_Score_Train_data_svr,\n",
        "        R2_Score_Train_data_rfr\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics)\n",
        "display(df_metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJFuD23o_brq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot R2 scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"Model\", y=\"R2 Test\", data=df_metrics, color='salmon', label=\"Test\")\n",
        "sns.barplot(x=\"Model\", y=\"R2 Train\", data=df_metrics, color='lightblue', label=\"Train\")\n",
        "plt.title(\"R² Score Comparison\")\n",
        "plt.ylabel(\"R² Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}